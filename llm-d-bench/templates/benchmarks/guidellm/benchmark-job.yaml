{{- if and (eq .Values.jobType "benchmark") (eq .Values.benchmarkTool "guidellm") }}
---
apiVersion: batch/v1
kind: Job
metadata:
  name: {{ .Values.benchmark.name }}
  namespace: {{ .Values.namespace }}
  labels:
    app: llm-d-bench
    job-type: benchmark
    {{- if .Values.kueue.enabled }}
    kueue.x-k8s.io/queue-name: "{{ .Values.kueue.queueName }}"
    {{- end }}
spec:
  {{- if .Values.kueue.enabled }}
  suspend: true
  {{- end }}
  template:
    metadata:
      labels:
        app: llm-d-bench
        job: {{ .Values.benchmark.name }}
    spec:
      containers:
      - name: guidellm
        image: "{{ .Values.benchmark.image.repository }}:{{ .Values.benchmark.image.tag }}"
        env:
          - name: HF_CLI_TOKEN
            valueFrom:
              secretKeyRef:
                name: huggingface-token
                key: HF_CLI_TOKEN
          {{- range $key, $value := .Values.benchmark.env }}
          - name: {{ $key }}
            value: {{ $value | quote }}
          {{- end }}
        command: ["/bin/bash"]
        args:
          - -c
          - |
            set -euo pipefail

            export RUN_DIR="/results/run_$(date +%s)"
            mkdir -p ${RUN_DIR}
            export GUIDELLM__LOGGING__LOG_FILE="${RUN_DIR}/console.log"

            echo "[JOB] Creating cache directory..."
            mkdir -p /results/.huggingface
            export HF_HOME="/results/.huggingface"

            echo "[JOB] Logging into Hugging Face..."
            hf auth login --token $HF_CLI_TOKEN

            echo "[JOB] Command: guidellm benchmark run \
              {{- if .Values.benchmark.target }}
              --target {{ .Values.benchmark.target }} \
              {{- end }}
              {{- if .Values.benchmark.model }}
              --model {{ .Values.benchmark.model }} \
              {{- end }}
              {{- if .Values.benchmark.processor }}
              --processor {{ .Values.benchmark.processor }} \
              {{- end }}
              {{- if .Values.benchmark.backendType }}
              --backend-type {{ .Values.benchmark.backendType }} \
              {{- end }}
              {{- if .Values.benchmark.rateType }}
              --rate-type={{ .Values.benchmark.rateType }} \
              {{- end }}
              {{- if .Values.benchmark.rate }}
              --rate={{ if kindIs "slice" .Values.benchmark.rate }}{{ join "," .Values.benchmark.rate }}{{ else }}{{ .Values.benchmark.rate }}{{ end }} \
              {{- end }}
              {{- if .Values.benchmark.data }}
              --data={{ if kindIs "slice" .Values.benchmark.data }}{{ join "," .Values.benchmark.data }}{{ else }}{{ .Values.benchmark.data }}{{ end }} \
              {{- end }}
              {{- if .Values.benchmark.maxSeconds }}
              --max-seconds={{ .Values.benchmark.maxSeconds }} \
              {{- end }}
              {{- if .Values.benchmark.additionalArgs }}
              {{ .Values.benchmark.additionalArgs }} \
              {{- end }}
              --output-path \${RUN_DIR}/output.json"

            echo "[JOB] Running guidellm..."
            guidellm benchmark run \
              {{- if .Values.benchmark.target }}
              --target {{ .Values.benchmark.target }} \
              {{- end }}
              {{- if .Values.benchmark.model }}
              --model {{ .Values.benchmark.model }} \
              {{- end }}
              {{- if .Values.benchmark.processor }}
              --processor {{ .Values.benchmark.processor }} \
              {{- end }}
              {{- if .Values.benchmark.backendType }}
              --backend-type {{ .Values.benchmark.backendType }} \
              {{- end }}
              {{- if .Values.benchmark.rateType }}
              --rate-type={{ .Values.benchmark.rateType }} \
              {{- end }}
              {{- if .Values.benchmark.rate }}
              --rate={{ if kindIs "slice" .Values.benchmark.rate }}{{ join "," .Values.benchmark.rate }}{{ else }}{{ .Values.benchmark.rate }}{{ end }} \
              {{- end }}
              {{- if .Values.benchmark.data }}
              --data={{ if kindIs "slice" .Values.benchmark.data }}{{ join "," .Values.benchmark.data }}{{ else }}{{ .Values.benchmark.data }}{{ end }} \
              {{- end }}
              {{- if .Values.benchmark.maxSeconds }}
              --max-seconds={{ .Values.benchmark.maxSeconds }} \
              {{- end }}
              {{- if .Values.benchmark.additionalArgs }}
              {{ .Values.benchmark.additionalArgs }} \
              {{- end }}
              --output-path ${RUN_DIR}/output.json

            echo "[JOB] Output file checksum:"
            sha256sum "${RUN_DIR}/output.json" || echo "[JOB] Error: Failed to generate checksum"
            echo "[JOB] Results saved to ${RUN_DIR}"

            # Create a marker file to signal the s3-uploader to start
            echo "${RUN_DIR}" > /results/upload-marker

            echo "[JOB] Benchmark script finished. Waiting for S3 upload to complete..."
            # Wait for the sidecar to remove the marker file
            while [ -f "/results/upload-marker" ]; do
              sleep 5
            done
            echo "[JOB] S3 upload complete. Exiting."
        volumeMounts:
        - name: results
          mountPath: /results
        resources:
          requests:
            memory: "2Gi"
            cpu: "500m"
          limits:
            memory: "4Gi"
            cpu: "1000m"
      {{- if .Values.s3.enabled }}
      - name: s3-uploader
        image: "amazon/aws-cli:latest"
        env:
          - name: AWS_ACCESS_KEY_ID
            valueFrom:
              secretKeyRef:
                name: {{ .Values.s3.secretName }}
                key: AWS_ACCESS_KEY_ID
          - name: AWS_SECRET_ACCESS_KEY
            valueFrom:
              secretKeyRef:
                name: {{ .Values.s3.secretName }}
                key: AWS_SECRET_ACCESS_KEY
        command: ["/bin/bash"]
        args:
          - -c
          - |
            set -e
            DONE_FILE_PATH="/results/upload-marker"

            trap 'rm -f ${DONE_FILE_PATH}' EXIT

            echo "[JOB] S3 uploader started, waiting for benchmark to complete..."

            SECONDS=0
            while [ ! -f "${DONE_FILE_PATH}" ]; do
              echo -ne "[JOB] Waiting for benchmark completion marker (${SECONDS}s)\r"
              sleep 1
            done
            echo ""

            RUN_DIR=$(cat "${DONE_FILE_PATH}")
            OUTPUT_FILE="${RUN_DIR}/output.json"

            if [ -f "${OUTPUT_FILE}" ]; then
              echo "[JOB] Benchmark complete. Uploading results to S3 from ${OUTPUT_FILE}..."
              # Try to upload, but do not exit on error
              aws s3 cp "${OUTPUT_FILE}" "s3://{{ .Values.s3.bucket }}/llm-d-bench/$(basename ${RUN_DIR})/output.json" --region {{ .Values.s3.region }} || \
                echo "[JOB] Error: S3 upload failed. The job will still complete."
              echo "[JOB] Results successfully uploaded to S3 bucket: {{ .Values.s3.bucket }}"
            else
              echo "[JOB] Error: Output file not found at ${OUTPUT_FILE}. Skipping upload."
            fi

            echo "[JOB] S3 uploader finished."
        volumeMounts:
        - name: results
          mountPath: /results
        resources:
          requests:
            memory: "2Gi"
            cpu: "500m"
          limits:
            memory: "4Gi"
            cpu: "1000m"
      {{- end }}
      volumes:
      - name: results
        persistentVolumeClaim:
          claimName: {{ .Values.pvc.name }}
      restartPolicy: Never
      {{- if .Values.benchmark.nodeSelector }}
      nodeSelector:
        {{- toYaml .Values.benchmark.nodeSelector | nindent 8 }}
      {{- end }}
      {{- if .Values.benchmark.affinity }}
      affinity:
        {{- toYaml .Values.benchmark.affinity | nindent 8 }}
      {{- end }}
  backoffLimit: 2
{{- end }}
