# Example: Run a GuideLLM benchmark

namespace: keda
benchmarkTool: guidellm
jobType: benchmark

benchmark:
  name: llama-benchmark-test

  image:
    repository: "image_repo"
    tag: "latest"

  env:
    GUIDELLM__REQUEST_TIMEOUT: "1000"
    GUIDELLM__LOGGING__CONSOLE_LOG_LEVEL: "INFO"

  # GuideLLM benchmark parameters
  target: http://llama-3-3-70b-predictor.kserve-e2e-perf.svc.cluster.local:8080
  model: meta-llama/Llama-3.3-70B-Instruct
  processor: meta-llama/Llama-3.3-70B-Instruct
  backendType: openai_http
  rateType: concurrent
  rate: "1,50,100,200,300,500,650"
  data: "1000"
  maxSeconds: "600"

pvc:
  create: true
  name: guidellm-pvc
  size: 50Gi
