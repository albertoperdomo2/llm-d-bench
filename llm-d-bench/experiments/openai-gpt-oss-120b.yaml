# RedHatAI Llama-3.3-70B Instruct FP8 dynamic Baseline Benchmark Experiment
# Tests basic performance with simple token specifications

jobType: benchmark

benchmark:
  name: openai-gpt-oss-120b 

  # Target inference endpoint
  target: http://infra-inference-scheduling-inference-gateway-istio.llm-d-inference-scheduling.svc.cluster.local:80

  # Model configuration
  model: openai/gpt-oss-120b
  processor: openai/gpt-oss-120b 

  # Benchmark parameters
  rateType: concurrent
  rate: "1,50,100,200,300,500,650"
  data: "prompt_tokens=1000,output_tokens=1000"
  maxSeconds: "600"

  # Environment variables (optional)
  env:
    GUIDELLM__REQUEST_TIMEOUT: "1000"
    GUIDELLM__LOGGING__CONSOLE_LOG_LEVEL: "INFO"

# Log pod matching label for collecting logs from model serving pods
logPodMatchingLabel: "llm-d.ai/model=ms-inference-scheduling-llm-d-modelservice"

# PVC configuration
# Set create: true only for the first experiment run, then set to false to reuse
pvc:
  create: false
  name: guidellm-pvc
  size: "20Gi"
