# Example: GuideLLM Benchmark with MLflow Integration
#
# This example demonstrates how to run a GuideLLM benchmark with MLflow experiment tracking enabled.
#

namespace: llm-d-inference-scheduling

benchmark:
  name: mlflow-test

  image:
    repository: "image-registry.openshift-image-registry.svc:5000/llm-d-inference-scheduling/guidellm-custom"
    tag: "latest"
    pullPolicy: Always

  affinity: null

  # Target inference endpoint
  target: http://infra-inference-scheduling-inference-gateway-istio.llm-d-inference-scheduling.svc.cluster.local:80

  # Model configuration
  model: Qwen/Qwen3-0.6B
  processor: Qwen/Qwen3-0.6B

  # Benchmark parameters
  rateType: concurrent
  rate: "1"
  data: "prompt_tokens=1000,output_tokens=1000"
  maxSeconds: "60"

  # Environment variables (optional)
  env:
    GUIDELLM__REQUEST_TIMEOUT: "1000"
    GUIDELLM__LOGGING__CONSOLE_LOG_LEVEL: "INFO"
  
# MLflow experiment tracking configuration
mlflow:
  enabled: true
  trackingUri: "https://mlflow-mlflow.apps.aperdomo-lab.ibm.rhperfscale.org"
  # Experiment name (groups related benchmark runs together)
  experimentName: "qwen-0.6b-performance-testing"
  # Authentication secret (must exist in the same namespace)
  auth:
    secretName: "mlflow-auth"
    usernameKey: "admin-username"
    passwordKey: "admin-password"

  # S3 credentials for MLflow artifact store
  s3:
    # Secret name containing S3 credentials
    secretName: "mlflow-s3-secret"
    # Keys in the secret for S3 credentials
    accessKey: "access-key"
    secretKey: "secret-key"
    bucketNameKey: "bucket-name"
    regionKey: "region"

# Optional: Kueue batching
kueue:
  enabled: false
  queueName: "guidellm-jobs"
